{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "x_train = np.loadtxt(\"mnb_x_train.csv\")\n",
    "y_train = np.loadtxt(\"mnb_y_train.csv\")\n",
    "x_test = np.loadtxt(\"mnb_x_test.csv\")\n",
    "y_test = np.loadtxt(\"mnb_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_sk = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    result = {}\n",
    "    class_values = set(y_train)\n",
    "    result['total_data'] = len(y_train)\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        current_class_rows = (y_train == current_class)\n",
    "        x_train_current = x_train[current_class_rows]\n",
    "        num_features = x_train.shape[1]\n",
    "        temp = 0\n",
    "        for j in range(1, num_features+1):\n",
    "            result[current_class][j] = x_train_current[:, j-1].sum()\n",
    "            temp += result[current_class][j]\n",
    "        result[current_class]['total_count'] = temp\n",
    "        result[current_class]['num'] = current_class_rows.sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability(current_class, x, dictionary):\n",
    "    output = np.log(dictionary[current_class]['num']) - np.log(dictionary['total_data'])\n",
    "    num_features = len(dictionary[current_class].keys()) - 2\n",
    "    for j in range(1, num_features+1):\n",
    "        if x[j-1] > 0:\n",
    "            count_with_xj = dictionary[current_class][j] + 1\n",
    "            count_current_class = dictionary[current_class]['total_count'] + num_features\n",
    "            current_xj_prob = (np.log(count_with_xj) - np.log(count_current_class)) + np.log(x[j-1])\n",
    "            output += current_xj_prob\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictSinglePoint(x, dictionary):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if current_class == 'total_data':\n",
    "            continue\n",
    "        p_current_class = probability(current_class, x, dictionary)\n",
    "        if first_run or p_current_class > best_p:\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_test, dictionary):\n",
    "    y_pred = []\n",
    "    for x in x_test:\n",
    "        x_class = predictSinglePoint(x, dictionary)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_self = predict(x_test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.70      0.70       100\n",
      "        1.0       0.81      0.87      0.84       100\n",
      "        2.0       0.90      0.91      0.91       100\n",
      "        3.0       0.96      0.94      0.95       100\n",
      "        4.0       0.95      0.97      0.96       100\n",
      "        5.0       0.92      0.97      0.94       100\n",
      "        6.0       0.97      0.88      0.92       100\n",
      "        7.0       0.96      0.98      0.97       100\n",
      "        8.0       0.99      0.97      0.98       100\n",
      "        9.0       0.90      0.88      0.89       100\n",
      "       10.0       0.98      0.98      0.98       100\n",
      "       11.0       0.96      0.93      0.94       100\n",
      "       12.0       0.85      0.90      0.87       100\n",
      "       13.0       0.95      0.93      0.94       100\n",
      "       14.0       0.80      0.82      0.81       100\n",
      "       15.0       0.94      0.91      0.92       100\n",
      "       16.0       0.84      0.94      0.89       100\n",
      "       17.0       0.96      0.90      0.93       100\n",
      "       18.0       0.78      0.72      0.75       100\n",
      "       19.0       0.96      0.95      0.95       100\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2000\n",
      "\n",
      "[[70  0  0  0  0  0  0  0  0  0  1  0  0  0 19  0  4  0  6  0]\n",
      " [ 0 87  1  0  1  0  0  1  0  1  0  0  8  0  1  0  0  0  0  0]\n",
      " [ 0  1 91  0  2  2  0  0  0  0  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0 94  0  2  0  1  0  0  0  3  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 97  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0 97  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  7  0  0  1  0 88  0  0  2  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  1  0  1  0 98  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0 97  0  0  0  0  1  0  0  0  0  1  0]\n",
      " [ 0  3  2  0  0  1  1  0  0 88  0  0  1  0  0  4  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 98  0  0  0  1  0  0  1  0  0]\n",
      " [ 0  0  0  2  0  1  0  0  0  0  0 93  0  1  0  0  0  0  1  2]\n",
      " [ 0  8  0  0  1  0  1  0  0  0  0  0 90  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  2  0  2  0  0  0 93  0  0  0  0  1  0]\n",
      " [15  0  0  0  0  1  0  0  0  0  1  0  0  1 82  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  1  0  0  3  0  0  2  1  0 91  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 94  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1 90  8  0]\n",
      " [12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  3 72  0]\n",
      " [ 0  0  1  0  0  1  0  0  0  2  0  0  1  0  0  0  0  0  0 95]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred_sk))\n",
    "print(confusion_matrix(y_test, y_pred_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  0  0  0  0  0  0  0  0  0  1  0  0  0 30  0  5  0  5  0]\n",
      " [ 0 89  1  0  1  0  1  0  0  2  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 0  0 96  0  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 99  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 98  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  1 96  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  9  2  0  2  0 77  0  0  4  0  0  0  0  0  5  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0 99  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0 96  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  5  2  0  0  0  0  0  0 91  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 99  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0 97  0  0  0  0  0  0  1  0]\n",
      " [ 0  3  1  0  1  0  0  0  0  0  0  0 95  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1  0  0  0 96  0  1  0  0  1  0]\n",
      " [ 9  0  0  0  0  0  0  0  0  0  1  0  0  1 89  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  2  0  0  4  0  0  2  1  0 89  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 94  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 90  9  0]\n",
      " [10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  4 71  0]\n",
      " [ 0  0  2  0  0  2  0  0  1  1  0  0  0  2  0  1  0  0  0 91]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.59      0.66       100\n",
      "        1.0       0.84      0.89      0.86       100\n",
      "        2.0       0.85      0.96      0.90       100\n",
      "        3.0       0.98      0.99      0.99       100\n",
      "        4.0       0.94      0.98      0.96       100\n",
      "        5.0       0.96      0.96      0.96       100\n",
      "        6.0       0.96      0.77      0.86       100\n",
      "        7.0       0.99      0.99      0.99       100\n",
      "        8.0       0.98      0.96      0.97       100\n",
      "        9.0       0.88      0.91      0.89       100\n",
      "       10.0       0.98      0.99      0.99       100\n",
      "       11.0       0.99      0.97      0.98       100\n",
      "       12.0       0.90      0.95      0.93       100\n",
      "       13.0       0.95      0.96      0.96       100\n",
      "       14.0       0.75      0.89      0.81       100\n",
      "       15.0       0.91      0.89      0.90       100\n",
      "       16.0       0.82      0.94      0.87       100\n",
      "       17.0       0.96      0.90      0.93       100\n",
      "       18.0       0.79      0.71      0.75       100\n",
      "       19.0       0.98      0.91      0.94       100\n",
      "\n",
      "avg / total       0.91      0.91      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_self))\n",
    "print(classification_report(y_test, y_pred_self))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
